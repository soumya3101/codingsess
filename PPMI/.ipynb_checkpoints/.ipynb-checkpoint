{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPMI Gait Analysis\n",
    "This data set is part of the Parkinson's Progression Markers Initiative. Anat Mirelman, PhD, of Tel Aviv University is the PI. According to the study summary: \"The Gait study was proposed in order to obtain quantitative, objective motor measures that could inform on pre-clinical symptoms, progression markers, and dynamic changes of function throughout disease and potential modifiers and mediators of motor symptoms.\"\n",
    "\n",
    "Your goal is to examine the data and later implement some ML algorithms to try and classify PD patients from non-PD patients based on the gait measures.\n",
    "\n",
    "To learn more about PPMI, go here: http://www.ppmi-info.org/  \n",
    "To learn more about working with the data, go here: www.ppmi-info.org/wp-content/uploads/2015/12/PPMI-data-access-final.mp4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# seaborn is for making figures look really nice\n",
    "import seaborn as sns\n",
    "\n",
    "# this is a big hint for a later part of the exercise\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you need to import the necessary data sets. The gait data are the objective gait measures. The screening data contain information on all of the individuals participating in PPMI.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      PATNO  APPRDX  CURRENT_APPRDX  BIRTHDT  GENDER ORIG_ENTRY  \\\n",
      "0      3400     1.0             1.0   1971.0     0.0    06/2010   \n",
      "1      3401     2.0             2.0   1954.0     1.0    06/2010   \n",
      "2      3402     3.0             3.0   1964.0     2.0    06/2010   \n",
      "3      3403     1.0             1.0   1941.0     2.0    06/2010   \n",
      "4      3404     2.0             2.0   1954.0     0.0    06/2010   \n",
      "...     ...     ...             ...      ...     ...        ...   \n",
      "2249   5012     9.0             9.0   1952.0     2.0    09/2019   \n",
      "2250   5013     9.0             9.0   1962.0     2.0    09/2019   \n",
      "2251   5014     9.0             9.0   1953.0     2.0    11/2019   \n",
      "2252   5015     9.0             9.0   1956.0     1.0    11/2019   \n",
      "2253   5016     9.0             9.0   1945.0     1.0    11/2019   \n",
      "\n",
      "                LAST_UPDATE  \n",
      "0     2010-12-17 10:58:57.0  \n",
      "1     2010-07-20 08:09:56.0  \n",
      "2     2011-09-27 12:12:25.0  \n",
      "3     2010-07-20 08:35:45.0  \n",
      "4     2010-07-20 09:00:48.0  \n",
      "...                     ...  \n",
      "2249  2019-09-27 08:31:52.0  \n",
      "2250  2019-09-27 10:51:18.0  \n",
      "2251  2019-11-19 11:26:48.0  \n",
      "2252  2019-11-20 09:20:16.0  \n",
      "2253  2019-11-22 08:11:48.0  \n",
      "\n",
      "[2254 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# read in csv files as pandas data frames\n",
    "# uploading the data from the gait parameters file\n",
    "gaitvariable= pd.read_csv(r'C:\\Users\\bhats\\OneDrive\\Documents\\GitHub\\codingsess\\PPMI/Gait_Data___Arm_swing.csv')\n",
    "#uploading all the data from the PD screening file with relevant data\n",
    "PDScreeningData=pd.read_csv(r'C:\\Users\\bhats\\OneDrive\\Documents\\GitHub\\codingsess\\PPMI/Screening___Demographics.csv',usecols=['PATNO','APPRDX','CURRENT_APPRDX','BIRTHDT','GENDER','ORIG_ENTRY','LAST_UPDATE'])\n",
    "\n",
    "# take a look at the variables in each csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why we have to read in both csv files is because the gait csv does not contain all of the necessary information we want about the subjects. For instance, we don't know from the gait data what diagnosis each individual has received. This is a problem if we later want to classify PD vs non-PD. The diagnosis information is contained within the screening csv. The trick is that there are a lot of subjects in the screening csv that were not part of the gait study. ***What to do?***\n",
    "\n",
    "My advice is to:  \n",
    "1) Get rid of the variables from the screening csv that we don't want or need.   \n",
    "2) Merge the two data frames into one that has both gait and screening data for all of the subjects in the gait study.\n",
    "\n",
    "**Hint:** Every individual in PPMI has a unique ID that is contained in 'PATNO'. The diagnosis each subject initially received is in 'APPRDX' and their most current diagnosis i in 'CURRENT_APPRDX'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From screening data, we only care about a few variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probably want to keep 'PATNO', 'APPRDX', 'CURRENT_APPRDX', 'BIRTHDT', 'GENDER', 'ORIG_ENTRY', 'LAST_UPDATE'\n",
    "\n",
    "# Now create new dataframe that only includes patients common to both gait and screen\n",
    "\n",
    "# Some subjects were tested on multiple visits. How many unique subjects are there? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see if any subjects changed diagnoses within the course of the study. If so, drop one of the diagnosis columns. \n",
    "\n",
    "It also makes sense to subset the data so that you can look at data only from each subjects' initial visit. How are you going to do this? **Hint:** You will need to reformat the dates so that they are in a format that python/pandas will understand as datetime. **Extra hint:** You will probably want to use the datetime.strptime function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first need to format the dates correctly. \n",
    "\n",
    "# Next we want to create new data frame with only first visit's data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be a good idea to print out a csv of the baseline data at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print df to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right. At this piont, you can probably appreciate that data wrangling isn't easy. But now that we have a slice of the data that we're interested in, let's start to look at the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.info() and df.columns are a good place to start -- you should probably have used them earlier, too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the large number of predictors, you might want to start looking for correlations among the data. \n",
    "# Try plotting a correlation matrix using a seaborn function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of patients with each diagnosis\n",
    "\n",
    "# Count how many subjects have missing data\n",
    "\n",
    "# Create new data frame that excludes subjects with missing data\n",
    "\n",
    "# Now how many subjects are there per group?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the presentation on accessing PPMI data (\"08b_v2_Caspell_Foster_PPMI-Data-Access_May-2015-v2.0.pdf\"), the APPRDX codes in our data set correspond to:\n",
    "\n",
    "**4 - Prodromal (this means an individual who appears at risk for PD based on report of \"anosmia\" or disrupted REM behavior)**\n",
    "\n",
    "**5 - Genetic Cohort subject with PD**\n",
    "\n",
    "**6 - Genetic Cohort subject unaffected**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on above diagnoses, we want to classify subjects as either having PD (APPRDX = 5) or no PD (APPRDX = 4 or 6)\n",
    "# Create a new column called PD. For each subject, PD takes a value of 1 for those with PD and 0 for those without.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have your labelled data (identifying each subject as having PD or no PD) you can now start thinking about building an ML algorithm to predict the diagnosis based on the gait data. The basic idea is that you wait train your algorithm on a portion of the data and then see how well it predicts a dignosis of PD on the out-of-sample (i.e., \"test\") data. A good first classification algorithm to learn and use is **logistic regression.** \n",
    "\n",
    "But before you learn about logistic regression, you should probably learn the ins and outs of linear regression. For that, and all other things ML, I highly recommend \"Introduction to Statistical Learning\" by James, Witten, Hastie and Tibshirani.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
